{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ali/anaconda3/envs/graph_rag/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(state,topic):\n",
    "    \"\"\"\n",
    "    A function to generate data;\n",
    "    \"\"\"\n",
    "    state['topic'] = topic\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a data generator agent that get topic from a user and generate a detail about it.\",\n",
    "        ),\n",
    "        (\"human\", \"Generate a description for {topic}\"),\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm\n",
    "    ai_msg = chain.invoke({\"topic\":topic})\n",
    "    return ai_msg.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = get_data(state,\"Neural Network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "state['data'] = description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 'Neural networks are a type of artificial intelligence that are designed to mimic the way the human brain operates. They consist of interconnected nodes, or artificial neurons, which work together to process complex information and make decisions. Neural networks are capable of learning from data, which allows them to recognize patterns, make predictions, and solve difficult problems. They are used in a wide range of applications, including image and speech recognition, natural language processing, and autonomous vehicles. Neural networks have become increasingly popular in recent years due to their ability to perform tasks that were previously thought to be impossible for computers.',\n",
       " 'topic': 'Neural Network'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's another example, but with a compound typed field.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scenario_generator(state):\n",
    "    \"\"\"\n",
    "    An Experience Scenario maker that design scenario for interview.\n",
    "    \"\"\"\n",
    "    class Scenario(BaseModel):\n",
    "        scenario: str = Field(description=\"The generated scenario for paticular topic\")\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a professional examiner and interviewer. You will make a detail secenario\"\n",
    "            \"The scenario will explain the real world sitation about given topic and base generated data\"\n",
    "            \"Please keep scenario concise and short like upto 3 sentences\"\n",
    "            \"You will return scenario in json with key scenario\"\n",
    "        ),\n",
    "        (\"human\", \"Generate realworld scenario for exam on {topic} with base data {data}\"),\n",
    "    ]\n",
    "    )\n",
    "    parser = PydanticOutputParser(pydantic_object=Scenario) \n",
    "    chain = prompt | llm | parser\n",
    "    ai_msg = chain.invoke({\"topic\":state['topic'],'data':state['data']})\n",
    "    state['scenario'] = ai_msg.scenario\n",
    "    return ai_msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = scenario_generator(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_generator(state):\n",
    "    \"\"\"\n",
    "    You are an examiner and you need evaluate a candiate 's knowledge of a particular subject.\n",
    "    You will ask questions based on given scenario, and data. \n",
    "    Also you will have access to previous asked questions. There might be previous asked questions.\n",
    "    You will not answer question your self. You also will not help user in question.\n",
    "    \"\"\"\n",
    "\n",
    "    state['questions'] = state.get('questions',[])\n",
    "    class QuestionObj(BaseModel):\n",
    "        question: str = Field(description=\"The generated question for paticular topic\")\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a professional examiner and interviewer. You will ask question one at a time.\"\n",
    "            \"You will ask questions based on given scenario, and data.\"\n",
    "            \"Also you will have access to previous asked questions. There might be previous asked questions.\"\n",
    "            \"You will not answer question your self. You also will not help user in question.\"\n",
    "            \"You will create a json output with key question\"\n",
    "        ),\n",
    "        (\"human\", \"Generate realworld scenario for exam on {topic} with base data {data} and previous questions  {previous_questions}\"),\n",
    "    ]\n",
    "    )\n",
    "    parser = PydanticOutputParser(pydantic_object=QuestionObj) \n",
    "    chain = prompt | llm | parser\n",
    "    ai_msg = chain.invoke({\"topic\":state['topic'],'data':state['data'],'previous_questions':state['questions']})\n",
    "    state['questions'].append(ai_msg.question)\n",
    "    return ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionObj(question='How can neural networks be used in image recognition applications?')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_generator(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 'Neural networks are a type of artificial intelligence that are designed to mimic the way the human brain operates. They consist of interconnected nodes, or artificial neurons, which work together to process complex information and make decisions. Neural networks are capable of learning from data, which allows them to recognize patterns, make predictions, and solve difficult problems. They are used in a wide range of applications, including image and speech recognition, natural language processing, and autonomous vehicles. Neural networks have become increasingly popular in recent years due to their ability to perform tasks that were previously thought to be impossible for computers.',\n",
       " 'topic': 'Neural Network',\n",
       " 'scenario': 'A tech company is developing a new neural network model for autonomous vehicles. The neural network is trained on a large dataset of images and sensor data collected from various driving scenarios. The company is conducting exams to evaluate the performance of the neural network in real-world conditions and ensure its reliability for use in autonomous vehicles.',\n",
       " 'questions': ['How can neural networks be used in image recognition applications?']}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionObj(question='What role do neural networks play in natural language processing applications?')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_generator(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 'Neural networks are a type of artificial intelligence that are designed to mimic the way the human brain operates. They consist of interconnected nodes, or artificial neurons, which work together to process complex information and make decisions. Neural networks are capable of learning from data, which allows them to recognize patterns, make predictions, and solve difficult problems. They are used in a wide range of applications, including image and speech recognition, natural language processing, and autonomous vehicles. Neural networks have become increasingly popular in recent years due to their ability to perform tasks that were previously thought to be impossible for computers.',\n",
       " 'topic': 'Neural Network',\n",
       " 'scenario': 'A tech company is developing a new neural network model for autonomous vehicles. The neural network is trained on a large dataset of images and sensor data collected from various driving scenarios. The company is conducting exams to evaluate the performance of the neural network in real-world conditions and ensure its reliability for use in autonomous vehicles.',\n",
       " 'questions': ['How can neural networks be used in image recognition applications?',\n",
       "  'What role do neural networks play in natural language processing applications?']}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "def router_node(user_input,state):\n",
    "    \"\"\"\n",
    "    You are a router node that need to decide  which path to take.\n",
    "    \"\"\"\n",
    "    \n",
    "    state['questions'] = state.get('',[])\n",
    "    class PathObj(BaseModel):\n",
    "        next_node: Literal['QUESTION_NODE','LLM_NODE','CLARIFICATION_NODE'] = Field(default=\"QUESTION_NODE\", description=\"Which path to take\")\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are router node. You have a list of path and you need to decide which path to follows.\"\n",
    "            \"You have acces to questions. If user response is related particular to question that is mentioned go to QUESTION_NODE\"\n",
    "            \"If user response is general then go to LLM Node\"\n",
    "            \"If user is asking for some clarification then go to  CLARIFICATION_NODE\"\n",
    "            \"The available options are ['QUESTION_NODE','LLM_NODE','CLARIFICATION_NODE']\"\n",
    "            \"You will create a json output with key next_node\"\n",
    "        ),\n",
    "        # (\"human\", \"Generate realworld scenario for exam on {topic} with base data {data} and previous questions  {previous_questions}\"),\n",
    "        (\"human\", \"What will be next state {input}, Available options  are ['QUESTION_NODE','LLM_NODE','CLARIFICATION_NODE']. This is list of given question {question}\"),\n",
    "    ]\n",
    "    )\n",
    "    parser = PydanticOutputParser(pydantic_object=PathObj) \n",
    "    chain = prompt | llm | parser\n",
    "    given_question = state['questions'][-1] if len(state['questions']) > 0 else []\n",
    "    ai_msg = chain.invoke({\"input\":user_input,'question':given_question})\n",
    "    return ai_msg.next_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 'Neural networks are a type of artificial intelligence that are designed to mimic the way the human brain operates. They consist of interconnected nodes, or artificial neurons, which work together to process complex information and make decisions. Neural networks are capable of learning from data, which allows them to recognize patterns, make predictions, and solve difficult problems. They are used in a wide range of applications, including image and speech recognition, natural language processing, and autonomous vehicles. Neural networks have become increasingly popular in recent years due to their ability to perform tasks that were previously thought to be impossible for computers.',\n",
       " 'topic': 'Neural Network',\n",
       " 'scenario': 'A tech company is developing a new neural network model for autonomous vehicles. The neural network is trained on a large dataset of images and sensor data collected from various driving scenarios. The company is conducting exams to evaluate the performance of the neural network in real-world conditions and ensure its reliability for use in autonomous vehicles.',\n",
       " 'questions': ['How can neural networks be used in image recognition applications?',\n",
       "  'What role do neural networks play in natural language processing applications?']}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_response = 'Hi How are u?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CLARIFICATION_NODE'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_node('I think image processing',state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clarification_node(restate_input,user_response):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    class RestateOutput(BaseModel):\n",
    "        restated_text: str = Field(description=\"The rephrased text\")\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a professional examiner and interviewer. You asked a question / scenario and user did not understand it.\"\n",
    "            \"You need to restate or rephrase it in easy words.\"\n",
    "            \"You will not tell answer\"\n",
    "            \"User can lead you to tell answer but you will only help in understanding question\"\n",
    "            \"Response should be in json and contain key  restated_text\"\n",
    "        ),\n",
    "        (\"human\", \"Rephrase the {restate_input} and user respond this {user_response}\"),\n",
    "    ]\n",
    "    )\n",
    "    parser = PydanticOutputParser(pydantic_object=RestateOutput) \n",
    "    chain = prompt | llm | parser\n",
    "    ai_msg = chain.invoke({\"restate_input\":restate_input,'user_response':user_response})\n",
    "    return ai_msg.restated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How are neural networks used in applications involving understanding and processing human language?'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clarification_node('What role do neural networks play in natural language processing applications?','I could not understand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = ChatMessageHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_conversation_agent(chat_history):\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an helpfull Exam bot and Your are taking user exam.\"\n",
    "            \"You need to help user with his query. But you will not answer to any his question related to exam\"\n",
    "            \"You will also not give him/her hint. Be specific to general chat if user do.\"\n",
    "            \"And you bring him/her toward exam\"\n",
    "            \"Your output should be in json with key 'text_msg'. Always try to respond in json\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm \n",
    "    ai_msg = chain.invoke({'chat_history':chat_history.messages})\n",
    "    return ai_msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = 'Hi'\n",
    "chat_history.add_user_message(msg)\n",
    "ai_msg = general_conversation_agent(chat_history)\n",
    "chat_history.add_ai_message(ai_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = 'Tell me about pizza'\n",
    "chat_history.add_user_message(msg)\n",
    "ai_msg = general_conversation_agent(chat_history)\n",
    "chat_history.add_ai_message(ai_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = 'What is your purpose?'\n",
    "chat_history.add_user_message(msg)\n",
    "ai_msg = general_conversation_agent(chat_history)\n",
    "chat_history.add_ai_message(ai_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"text_msg\": \"I\\'m here to assist you with any queries or tasks you may have. How can I help you today?\"\\n}'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = 'Summarize the chat'\n",
    "chat_history.add_user_message(msg)\n",
    "ai_msg = general_conversation_agent(chat_history)\n",
    "chat_history.add_ai_message(ai_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExamBotStateMachine:\n",
    "    def __init__(self) -> None:\n",
    "        self.state = {}\n",
    "        self.construct_state()\n",
    "\n",
    "    def construct_state(self):\n",
    "        self.state  = {\n",
    "            'topic':'',\n",
    "            'data': '',\n",
    "            'scenario':'',\n",
    "            'questions':[],\n",
    "            'answers': [],\n",
    "            'chat_history': ChatMessageHistory()\n",
    "        }\n",
    "\n",
    "    def forward(self,user_input):\n",
    "        pass\n",
    "    \n",
    "    def add_topic(self,topic):\n",
    "        self.state['topic'] = topic\n",
    "    \n",
    "    def get_data(self):\n",
    "        \"\"\"\n",
    "        A function to generate data;\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a data generator agent that get topic from a user and generate a detail about it.\",\n",
    "            ),\n",
    "            (\"human\", \"Generate a description for {topic}\"),\n",
    "        ]\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm\n",
    "        ai_msg = chain.invoke({\"topic\":self.state['topic']})\n",
    "        return ai_msg.content\n",
    "    \n",
    "\n",
    "    def scenario_generator(self):\n",
    "        \"\"\"\n",
    "        An Experience Scenario maker that design scenario for interview.\n",
    "        \"\"\"\n",
    "        class Scenario(BaseModel):\n",
    "            scenario: str = Field(description=\"The generated scenario for paticular topic\")\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a professional examiner and interviewer. You will make a detail secenario\"\n",
    "                \"The scenario will explain the real world sitation about given topic and base generated data\"\n",
    "                \"Please keep scenario concise and short like upto 3 sentences\"\n",
    "                \"You will return scenario in json with key scenario\"\n",
    "            ),\n",
    "            (\"human\", \"Generate realworld scenario for exam on {topic} with base data {data}\"),\n",
    "        ]\n",
    "        )\n",
    "        parser = PydanticOutputParser(pydantic_object=Scenario) \n",
    "        chain = prompt | llm | parser\n",
    "        ai_msg = chain.invoke({\"topic\":self.state['topic'],'data':self.state['data']})\n",
    "        self.state['scenario'] = ai_msg.scenario\n",
    "        return ai_msg\n",
    "    \n",
    "    def question_generator(self):\n",
    "        \"\"\"\n",
    "        You are an examiner and you need evaluate a candiate 's knowledge of a particular subject.\n",
    "        You will ask questions based on given scenario, and data. \n",
    "        Also you will have access to previous asked questions. There might be previous asked questions.\n",
    "        You will not answer question your self. You also will not help user in question.\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        class QuestionObj(BaseModel):\n",
    "            question: str = Field(description=\"The generated question for paticular topic\")\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a professional examiner and interviewer. You will ask question one at a time.\"\n",
    "                \"You will ask questions based on given scenario, and data.\"\n",
    "                \"Also you will have access to previous asked questions. There might be previous asked questions.\"\n",
    "                \"You will not answer question your self. You also will not help user in question.\"\n",
    "                \"You will create a json output with key question\"\n",
    "            ),\n",
    "            (\"human\", \"Generate realworld scenario for exam on {topic} with base data {data} and previous questions  {previous_questions}\"),\n",
    "        ]\n",
    "        )\n",
    "        parser = PydanticOutputParser(pydantic_object=QuestionObj) \n",
    "        chain = prompt | llm | parser\n",
    "        ai_msg = chain.invoke({\"topic\":self.state['topic'],'data':self.state['data'],\n",
    "                               'previous_questions':self.state['questions']})\n",
    "        self.state['questions'].append(ai_msg.question)\n",
    "        return ai_msg\n",
    "    \n",
    "    def router_node(self,user_input):\n",
    "        \"\"\"\n",
    "        You are a router node that need to decide  which path to take.\n",
    "        \"\"\"\n",
    "        \n",
    "        class PathObj(BaseModel):\n",
    "            next_node: Literal['QUESTION_NODE','LLM_NODE','CLARIFICATION_NODE'] = Field(default=\"QUESTION_NODE\", description=\"Which path to take\")\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are router node. You have a list of path and you need to decide which path to follows.\"\n",
    "                \"You have acces to questions. If user response is related particular to question that is mentioned go to QUESTION_NODE\"\n",
    "                \"If user response is general then go to LLM Node\"\n",
    "                \"If user is asking for some clarification then go to  CLARIFICATION_NODE\"\n",
    "                \"The available options are ['QUESTION_NODE','LLM_NODE','CLARIFICATION_NODE']\"\n",
    "                \"You will create a json output with key next_node\"\n",
    "            ),\n",
    "            # (\"human\", \"Generate realworld scenario for exam on {topic} with base data {data} and previous questions  {previous_questions}\"),\n",
    "            (\"human\", \"What will be next state {input}, Available options  are ['QUESTION_NODE','LLM_NODE','CLARIFICATION_NODE']. This is list of given question {question}\"),\n",
    "        ]\n",
    "        )\n",
    "        parser = PydanticOutputParser(pydantic_object=PathObj) \n",
    "        chain = prompt | llm | parser\n",
    "        given_question = self.state['questions'][-1] if len(self.state['questions']) > 0 else []\n",
    "        ai_msg = chain.invoke({\"input\":user_input,'question':given_question})\n",
    "        return ai_msg.next_node\n",
    "    \n",
    "    def clarification_node(self,restate_input,user_response):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        class RestateOutput(BaseModel):\n",
    "            restated_text: str = Field(description=\"The rephrased text\")\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a professional examiner and interviewer. You asked a question / scenario and user did not understand it.\"\n",
    "                \"You need to restate or rephrase it in easy words.\"\n",
    "                \"You will not tell answer\"\n",
    "                \"User can lead you to tell answer but you will only help in understanding question\"\n",
    "                \"Response should be in json and contain key  restated_text\"\n",
    "            ),\n",
    "            (\"human\", \"Rephrase the {restate_input} and user respond this {user_response}\"),\n",
    "        ]\n",
    "        )\n",
    "        parser = PydanticOutputParser(pydantic_object=RestateOutput) \n",
    "        chain = prompt | llm | parser\n",
    "        ai_msg = chain.invoke({\"restate_input\":restate_input,'user_response':user_response})\n",
    "        return ai_msg.restated_text\n",
    "    \n",
    "    def general_conversation_agent(self):\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are an helpfull Exam bot and Your are taking user exam.\"\n",
    "                \"You need to help user with his query. But you will not answer to any his question related to exam\"\n",
    "                \"You will also not give him/her hint. Be specific to general chat if user do.\"\n",
    "                \"And you bring him/her toward exam\"\n",
    "                \"Your output should be in json with key 'text_msg'. Always try to respond in json\"\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        ]\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm \n",
    "        ai_msg = chain.invoke({'chat_history':self.state['chat_history'].messages})\n",
    "        return ai_msg.content\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
